{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U --quiet langchain-community tiktoken langchain-openai langchainhub chromadb langchain langgraph langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def _set_env(key: str):\n",
    "    if key not in os.environ:\n",
    "        os.environ[key] = getpass.getpass(f\"{key}:\")\n",
    "\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Downloading pypdf-5.9.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in /Users/azeez/miniforge3/lib/python3.10/site-packages (from pypdf) (4.12.2)\n",
      "Downloading pypdf-5.9.0-py3-none-any.whl (313 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.2/313.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: pypdf\n",
      "Successfully installed pypdf-5.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFDirectoryLoader, PyPDFLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './pdfs/human-agent-collab-problem-solving.pdf'\n",
    "\n",
    "docs = PyPDFLoader(file_path).load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-02-21T01:47:05+00:00', 'author': '', 'keywords': '', 'moddate': '2024-02-21T01:47:05+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': './pdfs/human-agent-collab-problem-solving.pdf', 'total_pages': 16, 'page': 0, 'page_label': '1'}, page_content='Large Language Model-based Human-Agent Collaboration\\nfor Complex Task Solving\\nXueyang Feng1,2∗, Zhi-Yuan Chen1,2∗, Yujia Qin3, Yankai Lin1,2†\\nXu Chen1,2†, Zhiyuan Liu3, Ji-Rong Wen1,2\\n1Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China\\n2 Beijing Key Laboratory of Big Data Management and Analysis Methods, Beijing, China\\n3 Department of Computer Science and Technology, Tsinghua University, Beijing, China\\n{xueyangfeng, zhiyuanc2001, yankailin, xu.chen}@ruc.edu.cn\\nAbstract\\nIn recent developments within the research\\ncommunity, the integration of Large Language\\nModels (LLMs) in creating fully autonomous\\nagents has garnered significant interest. De-\\nspite this, LLM-based agents frequently demon-\\nstrate notable shortcomings in adjusting to dy-\\nnamic environments and fully grasping hu-\\nman needs. In this work, we introduce the\\nproblem of LLM-based human-agent collab-\\noration for complex task-solving, exploring\\ntheir synergistic potential. In addition, we pro-\\npose a Reinforcement Learning-based Human-\\nAgent Collaboration method, ReHAC. This\\napproach includes a policy model designed to\\ndetermine the most opportune stages for hu-\\nman intervention within the task-solving pro-\\ncess. We construct a human-agent collabo-\\nration dataset to train this policy model in\\nan offline reinforcement learning environment.\\nOur validation tests confirm the model’s ef-\\nfectiveness. The results demonstrate that the\\nsynergistic efforts of humans and LLM-based\\nagents significantly improve performance in\\ncomplex tasks, primarily through well-planned,\\nlimited human intervention. Datasets and code\\nare available at: https://github.com/\\nXueyangFeng/ReHAC.\\n1 Introduction\\nIn today’s increasingly complex world, humans are\\nconfronted with multifaceted tasks stemming from\\ntechnical, social, and economic domains. Solv-\\ning these complex tasks necessitates not only hu-\\nman interaction with the environment but also in-\\ntricate decision-making processes. To alleviate\\nhuman workload and enhance the automation of\\ntasks in both professional and personal spheres, re-\\nsearchers have been actively developing advanced\\ntools for human assistance (Zawacki-Richter et al.,\\n∗ Equal Contribution. The order is determined by dice\\nrolling.\\n† Corresponding Authors.\\nAgentHuman Env\\nAllocator Env\\nEnv\\n(a)\\nActAct\\n(b)\\n(c)\\nAgent\\nHuman\\nAct\\nAct\\nI need help\\nFigure 1: Different Levels of Automation. (a) No au-\\ntomation: Tasks are entirely performed by humans. (b)\\nFull automation: Tasks are completely executed by\\nagents without human intervention. (c) Conditional\\nautomation: Humans are required only for specific sub-\\ntasks, without continuous monitoring.\\n2019; Amershi et al., 2019). Recently, the emer-\\ngence of Large Language Models (LLMs) such\\nas LLaMA (Touvron et al., 2023), Gemini (Team\\net al., 2023) and GPT (Brown et al., 2020; Achiam\\net al., 2023) has marked a significant milestone.\\nLLMs’ remarkable abilities in task understanding,\\nplanning, and reasoning (Zhao et al., 2023b) have\\ngiven rise to the development of LLM-based au-\\ntonomous agents (Wang et al., 2023a; Yao et al.,\\n2022; Shinn et al., 2023). These agents are de-\\nsigned to leverage the LLMs’ capabilities to assist\\nhumans in solving complex tasks autonomously.\\nThe LLMs’ capabilities enable them to effectively\\nnavigate and address the complexities encountered\\nin real-world scenarios, thereby offering substan-\\ntial support in human decision-making processes\\nof task-solving.\\nDespite the remarkable progress of LLM-based\\nagents, there remains a notable gap in their intelli-\\ngence level to handle complex and dynamic real-\\nworld tasks with human-like proficiency. This limi-\\ntation poses a significant challenge to their practi-\\ncality in real-world applications, especially in sce-\\narXiv:2402.12914v1  [cs.CL]  20 Feb 2024')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to vectorDB\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=docs,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=OpenAIEmbeddings(),\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    'retrieve_info_from_papers',\n",
    "    'Search and return information about a paper discussing usage of LLMs for human collaborative problem solving.',\n",
    ")\n",
    "\n",
    "tools = [retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Sequence, TypedDict\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    # The add_messages function defines how an update should be processed\n",
    "    # Default is to replace. add_messages says \"append\"\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
